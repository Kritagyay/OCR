{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":72550,"databundleVersionId":7950640,"sourceType":"competition"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, Reshape\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport joblib\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.229232Z","iopub.execute_input":"2024-03-16T15:27:55.229588Z","iopub.status.idle":"2024-03-16T15:27:55.23594Z","shell.execute_reply.started":"2024-03-16T15:27:55.229562Z","shell.execute_reply":"2024-03-16T15:27:55.234886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels=pd.read_csv(\"/kaggle/input/mlware24/train-labels_mlware.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.237854Z","iopub.execute_input":"2024-03-16T15:27:55.238224Z","iopub.status.idle":"2024-03-16T15:27:55.274383Z","shell.execute_reply.started":"2024-03-16T15:27:55.238191Z","shell.execute_reply":"2024-03-16T15:27:55.273652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.275905Z","iopub.execute_input":"2024-03-16T15:27:55.276174Z","iopub.status.idle":"2024-03-16T15:27:55.281873Z","shell.execute_reply.started":"2024-03-16T15:27:55.276151Z","shell.execute_reply":"2024-03-16T15:27:55.280988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.28291Z","iopub.execute_input":"2024-03-16T15:27:55.283156Z","iopub.status.idle":"2024-03-16T15:27:55.301559Z","shell.execute_reply.started":"2024-03-16T15:27:55.283135Z","shell.execute_reply":"2024-03-16T15:27:55.30065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.303648Z","iopub.execute_input":"2024-03-16T15:27:55.303922Z","iopub.status.idle":"2024-03-16T15:27:55.312915Z","shell.execute_reply.started":"2024-03-16T15:27:55.3039Z","shell.execute_reply":"2024-03-16T15:27:55.312016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.drop(\"Unnamed: 0\",axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.314313Z","iopub.execute_input":"2024-03-16T15:27:55.314938Z","iopub.status.idle":"2024-03-16T15:27:55.327555Z","shell.execute_reply.started":"2024-03-16T15:27:55.314905Z","shell.execute_reply":"2024-03-16T15:27:55.326688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(img_path):\n    return Image.open(img_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.328574Z","iopub.execute_input":"2024-03-16T15:27:55.328887Z","iopub.status.idle":"2024-03-16T15:27:55.336966Z","shell.execute_reply.started":"2024-03-16T15:27:55.32886Z","shell.execute_reply":"2024-03-16T15:27:55.336086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {}\nfor index, row in train_labels.iterrows():\n    # Get the image ID and label\n    image_id = row['image']\n    label = row['text']\n\n    # Load the image\n    images = load_image(f'/kaggle/input/mlware24/train_images_mlware/train_images/{image_id}')\n\n    # Store the image and label in the dictionary\n    data[image_id] = {'image': images, 'label': label}\n\n# Print the first 5 items in the dictionary to verify the data\nfor key in list(data.keys())[:5]:\n    print(key, data[key]['label'])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:27:55.338023Z","iopub.execute_input":"2024-03-16T15:27:55.338293Z","iopub.status.idle":"2024-03-16T15:28:23.076834Z","shell.execute_reply.started":"2024-03-16T15:27:55.33827Z","shell.execute_reply":"2024-03-16T15:28:23.075752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Specify the directory where the images are\nimage_dir = '/kaggle/input/mlware24/train_images_mlware/train_images/'\n\n# Get the list of image file names\nimage_files = os.listdir(image_dir)\n\n# Sort the image files\nimage_files.sort()\n\n# Display the first 5 images\nfor i in range(5):\n    # Open the image file\n    image = Image.open(os.path.join(image_dir, image_files[i]))\n    \n    # Display the image\n    plt.imshow(image)\n    plt.title(image_files[i])\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:28:23.07791Z","iopub.execute_input":"2024-03-16T15:28:23.078193Z","iopub.status.idle":"2024-03-16T15:28:24.712015Z","shell.execute_reply.started":"2024-03-16T15:28:23.07817Z","shell.execute_reply":"2024-03-16T15:28:24.711087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing.image import img_to_array\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:28:24.713242Z","iopub.execute_input":"2024-03-16T15:28:24.713533Z","iopub.status.idle":"2024-03-16T15:28:24.718656Z","shell.execute_reply.started":"2024-03-16T15:28:24.713506Z","shell.execute_reply":"2024-03-16T15:28:24.717666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array([img_to_array(data[key]['image'].convert('L').resize((50, 50))) for key in data.keys()])\nX = X.astype('float32') / 255\n\n# Encode labels using one-hot encoding\nlb = LabelBinarizer().fit(list(data[key]['label'] for key in data.keys()))\ny = lb.transform(list(data[key]['label'] for key in data.keys()))\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:28:24.723073Z","iopub.execute_input":"2024-03-16T15:28:24.723347Z","iopub.status.idle":"2024-03-16T15:28:46.930727Z","shell.execute_reply.started":"2024-03-16T15:28:24.723323Z","shell.execute_reply":"2024-03-16T15:28:46.929766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\n# Define the model\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=(50, 50, 1), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(len(lb.classes_), activation='softmax'))\n\n# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:28:46.932145Z","iopub.execute_input":"2024-03-16T15:28:46.932455Z","iopub.status.idle":"2024-03-16T15:28:47.922506Z","shell.execute_reply.started":"2024-03-16T15:28:46.932428Z","shell.execute_reply":"2024-03-16T15:28:47.921609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:28:47.923745Z","iopub.execute_input":"2024-03-16T15:28:47.92409Z","iopub.status.idle":"2024-03-16T15:29:46.330349Z","shell.execute_reply.started":"2024-03-16T15:28:47.924062Z","shell.execute_reply":"2024-03-16T15:29:46.329488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test)\nprint('Test loss:', loss)\nprint('Test accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:46.331495Z","iopub.execute_input":"2024-03-16T15:29:46.331821Z","iopub.status.idle":"2024-03-16T15:29:48.314685Z","shell.execute_reply.started":"2024-03-16T15:29:46.331795Z","shell.execute_reply":"2024-03-16T15:29:48.313603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a prediction for the first image in the test set\nprediction = model.predict(np.array([X_test[0]]))\n\n# The prediction is a one-hot encoded array, so we'll use the inverse_transform method to get the original label\npredicted_label = lb.inverse_transform(prediction)\n\nprint('Predicted label:', predicted_label)\nprint('Actual label:', lb.inverse_transform(np.array([y_test[0]])))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:48.316034Z","iopub.execute_input":"2024-03-16T15:29:48.316386Z","iopub.status.idle":"2024-03-16T15:29:49.009938Z","shell.execute_reply.started":"2024-03-16T15:29:48.316356Z","shell.execute_reply":"2024-03-16T15:29:49.008944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**so this code did'nt worked properly will do some more changes in the images as it is a graysclae image need to do some augumentation**","metadata":{}},{"cell_type":"code","source":"# Convert images to grayscale and resize them\nX = np.array([img_to_array(data[key]['image'].convert('L').resize((128, 128))) for key in data.keys()])\nX = X.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:49.011081Z","iopub.execute_input":"2024-03-16T15:29:49.011401Z","iopub.status.idle":"2024-03-16T15:29:56.639161Z","shell.execute_reply.started":"2024-03-16T15:29:49.011374Z","shell.execute_reply":"2024-03-16T15:29:56.638078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:56.6405Z","iopub.execute_input":"2024-03-16T15:29:56.640932Z","iopub.status.idle":"2024-03-16T15:29:56.650282Z","shell.execute_reply.started":"2024-03-16T15:29:56.640893Z","shell.execute_reply":"2024-03-16T15:29:56.649212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\n\n# Flatten the array of labels\nlabels = [data[key]['label'] for key in data.keys()]\n\n# Initialize the tokenizer\ntokenizer = Tokenizer(char_level=True,lower=False)\n\n# Fit the tokenizer on the labels\ntokenizer.fit_on_texts(labels)\n\n# Transform the labels to one-hot encoded vectors\ny = np.array([tokenizer.texts_to_matrix(label) for label in labels])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:56.651349Z","iopub.execute_input":"2024-03-16T15:29:56.651652Z","iopub.status.idle":"2024-03-16T15:29:57.247925Z","shell.execute_reply.started":"2024-03-16T15:29:56.651605Z","shell.execute_reply":"2024-03-16T15:29:57.246909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:57.250281Z","iopub.execute_input":"2024-03-16T15:29:57.251109Z","iopub.status.idle":"2024-03-16T15:29:57.268527Z","shell.execute_reply.started":"2024-03-16T15:29:57.251075Z","shell.execute_reply":"2024-03-16T15:29:57.267683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import LSTM, TimeDistributed, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.models import Sequential\n\n# Define the model\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))  # Changed from (128, 128, 3) to (128, 128, 1)\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1020, activation='relu'))\nmodel.add(Reshape((6, -1)))  # Reshape the output into sequences\nmodel.add(LSTM(128, return_sequences=True))\nmodel.add(TimeDistributed(Dense(len(tokenizer.word_index) + 1, activation='softmax')))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:57.269711Z","iopub.execute_input":"2024-03-16T15:29:57.269987Z","iopub.status.idle":"2024-03-16T15:29:57.610398Z","shell.execute_reply.started":"2024-03-16T15:29:57.269964Z","shell.execute_reply":"2024-03-16T15:29:57.609361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:57.611737Z","iopub.execute_input":"2024-03-16T15:29:57.612108Z","iopub.status.idle":"2024-03-16T15:29:57.966587Z","shell.execute_reply.started":"2024-03-16T15:29:57.612075Z","shell.execute_reply":"2024-03-16T15:29:57.965732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=50, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:29:57.967775Z","iopub.execute_input":"2024-03-16T15:29:57.968092Z","iopub.status.idle":"2024-03-16T15:46:58.256165Z","shell.execute_reply.started":"2024-03-16T15:29:57.968067Z","shell.execute_reply":"2024-03-16T15:46:58.255222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = '/kaggle/input/mlware24/test_images_mlware/test_images/'\n\ntest_files = os.listdir(test_dir)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:46:58.25732Z","iopub.execute_input":"2024-03-16T15:46:58.257647Z","iopub.status.idle":"2024-03-16T15:46:58.441624Z","shell.execute_reply.started":"2024-03-16T15:46:58.257602Z","shell.execute_reply":"2024-03-16T15:46:58.44091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\n\nfor file in test_files:\n    image = Image.open(os.path.join(test_dir, file)).convert('L').resize((128, 128))\n    \n    image = img_to_array(image) / 255.0\n    \n    prediction = model.predict(np.expand_dims(image, axis=0))\n    \n    predicted_label = ''.join(tokenizer.sequences_to_texts(prediction.argmax(axis=-1))).replace(' ', '')\n\n    predictions.append(predicted_label)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T15:46:58.442564Z","iopub.execute_input":"2024-03-16T15:46:58.442844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify the directory where the images are\nimage_dir = '/kaggle/input/mlware24/test_images_mlware/test_images/'\n\n# Get the list of image file names\nimage_files = os.listdir(image_dir)\n\n# Sort the image files\nimage_files.sort()\n\n# Display the first 5 images\nfor i in range(5):\n    # Open the image file\n    image = Image.open(os.path.join(image_dir, image_files[i]))\n    \n    # Display the image\n    plt.imshow(image)\n    plt.title(image_files[i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T16:15:19.193082Z","iopub.execute_input":"2024-03-16T16:15:19.193514Z","iopub.status.idle":"2024-03-16T16:15:20.399365Z","shell.execute_reply.started":"2024-03-16T16:15:19.193472Z","shell.execute_reply":"2024-03-16T16:15:20.398374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({\n    'Image': test_files,\n    'text': predictions\n})\n\n# Print the DataFrame\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T16:15:28.361225Z","iopub.execute_input":"2024-03-16T16:15:28.361935Z","iopub.status.idle":"2024-03-16T16:15:28.372311Z","shell.execute_reply.started":"2024-03-16T16:15:28.361898Z","shell.execute_reply":"2024-03-16T16:15:28.371122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open('/kaggle/input/mlware24/test_images_mlware/test_images/test-2144.png')\n\n# Display the image\nplt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T16:15:32.036755Z","iopub.execute_input":"2024-03-16T16:15:32.037149Z","iopub.status.idle":"2024-03-16T16:15:32.215172Z","shell.execute_reply.started":"2024-03-16T16:15:32.037121Z","shell.execute_reply":"2024-03-16T16:15:32.214158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('submission_file_mlware.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T16:15:39.366703Z","iopub.execute_input":"2024-03-16T16:15:39.3671Z","iopub.status.idle":"2024-03-16T16:15:39.38322Z","shell.execute_reply.started":"2024-03-16T16:15:39.36707Z","shell.execute_reply":"2024-03-16T16:15:39.38235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}